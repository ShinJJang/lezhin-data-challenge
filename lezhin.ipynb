{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from numpy import genfromtxt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    "    df = pd.read_csv(file_name, sep='\\t', header=None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deera\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2821: DtypeWarning: Columns (7,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "df = read_data('lezhin_public_dataset_training.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.iloc[:, :20]\n",
    "del df[7], df[8], df[16], df[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.169985e-01</td>\n",
       "      <td>1.327282e-01</td>\n",
       "      <td>2.840949e-01</td>\n",
       "      <td>1.115090e-01</td>\n",
       "      <td>2.589148e-01</td>\n",
       "      <td>2.636578e+00</td>\n",
       "      <td>7.994948e+01</td>\n",
       "      <td>-5.841105e+14</td>\n",
       "      <td>1.291841e-02</td>\n",
       "      <td>1.485504e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.166512e-05</td>\n",
       "      <td>6.843252e-02</td>\n",
       "      <td>5.184376e-03</td>\n",
       "      <td>2.199250e-06</td>\n",
       "      <td>3.106541e-05</td>\n",
       "      <td>2.997524e-04</td>\n",
       "      <td>1.249980e-01</td>\n",
       "      <td>3.696069e-02</td>\n",
       "      <td>4.047608e-07</td>\n",
       "      <td>4.232123e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.122018e-01</td>\n",
       "      <td>3.392809e-01</td>\n",
       "      <td>4.509824e-01</td>\n",
       "      <td>3.147615e-01</td>\n",
       "      <td>4.380389e-01</td>\n",
       "      <td>6.181888e+00</td>\n",
       "      <td>1.290465e+02</td>\n",
       "      <td>7.339708e+16</td>\n",
       "      <td>1.129227e-01</td>\n",
       "      <td>3.854197e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>1.123908e-03</td>\n",
       "      <td>1.463250e-01</td>\n",
       "      <td>3.121712e-02</td>\n",
       "      <td>4.712688e-04</td>\n",
       "      <td>2.538336e-03</td>\n",
       "      <td>8.295776e-03</td>\n",
       "      <td>2.005742e-01</td>\n",
       "      <td>7.977981e-02</td>\n",
       "      <td>1.090358e-04</td>\n",
       "      <td>8.696757e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.940000e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.060000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.560000e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.504000e-01</td>\n",
       "      <td>2.880000e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>6.574000e+03</td>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.883000e-01</td>\n",
       "      <td>8.586000e-01</td>\n",
       "      <td>9.111000e-01</td>\n",
       "      <td>4.424000e-01</td>\n",
       "      <td>5.783000e-01</td>\n",
       "      <td>8.418000e-01</td>\n",
       "      <td>9.545000e-01</td>\n",
       "      <td>7.078000e-01</td>\n",
       "      <td>1.044000e-01</td>\n",
       "      <td>4.217000e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 173 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2             3             4    \\\n",
       "count  1.279027e+06  1.279027e+06  1.279027e+06  1.279027e+06  1.279027e+06   \n",
       "mean   2.169985e-01  1.327282e-01  2.840949e-01  1.115090e-01  2.589148e-01   \n",
       "std    4.122018e-01  3.392809e-01  4.509824e-01  3.147615e-01  4.380389e-01   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    0.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00  1.000000e+00   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "                5             6             9             10            11   \\\n",
       "count  1.279027e+06  1.279027e+06  1.279027e+06  1.279027e+06  1.279027e+06   \n",
       "mean   2.636578e+00  7.994948e+01 -5.841105e+14  1.291841e-02  1.485504e-05   \n",
       "std    6.181888e+00  1.290465e+02  7.339708e+16  1.129227e-01  3.854197e-03   \n",
       "min    0.000000e+00  0.000000e+00 -9.223372e+18  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  3.000000e+01  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    0.000000e+00  1.060000e+02  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max    2.300000e+01  6.574000e+03  1.900000e+01  1.000000e+00  1.000000e+00   \n",
       "\n",
       "           ...                167           168           169           170  \\\n",
       "count      ...       1.279027e+06  1.279027e+06  1.279027e+06  1.279027e+06   \n",
       "mean       ...       1.166512e-05  6.843252e-02  5.184376e-03  2.199250e-06   \n",
       "std        ...       1.123908e-03  1.463250e-01  3.121712e-02  4.712688e-04   \n",
       "min        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%        ...       0.000000e+00  4.560000e-02  0.000000e+00  0.000000e+00   \n",
       "max        ...       3.883000e-01  8.586000e-01  9.111000e-01  4.424000e-01   \n",
       "\n",
       "                171           172           173           174           175  \\\n",
       "count  1.279027e+06  1.279027e+06  1.279027e+06  1.279027e+06  1.279027e+06   \n",
       "mean   3.106541e-05  2.997524e-04  1.249980e-01  3.696069e-02  4.047608e-07   \n",
       "std    2.538336e-03  8.295776e-03  2.005742e-01  7.977981e-02  1.090358e-04   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00  2.940000e-02  0.000000e+00  0.000000e+00   \n",
       "75%    0.000000e+00  0.000000e+00  1.504000e-01  2.880000e-02  0.000000e+00   \n",
       "max    5.783000e-01  8.418000e-01  9.545000e-01  7.078000e-01  1.044000e-01   \n",
       "\n",
       "                176  \n",
       "count  1.279027e+06  \n",
       "mean   4.232123e-06  \n",
       "std    8.696757e-04  \n",
       "min    0.000000e+00  \n",
       "25%    0.000000e+00  \n",
       "50%    0.000000e+00  \n",
       "75%    0.000000e+00  \n",
       "max    4.217000e-01  \n",
       "\n",
       "[8 rows x 173 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.15111543e-01   2.03385131e-01   9.90748072e-02   1.91878069e-01\n",
      "   3.82157440e+01   1.66529942e+04   5.38713173e+33   1.27515383e-02\n",
      "   1.48548331e-05   4.08220688e-02   1.02018734e-01   4.10086862e-02\n",
      "   3.25354759e-03   2.45624487e-01   4.74883876e+01   4.61867511e+01\n",
      "   6.06847586e+01   6.37896923e+01   3.75022068e+01   3.60551168e+01\n",
      "   4.33698589e+01   9.70587381e+01   1.86694818e+01   7.72218115e+01\n",
      "   2.60344947e+01   1.45445092e+01   1.19066626e+01   3.46125399e+01\n",
      "   6.31201610e+01   3.17641667e+01   7.50052257e+01   1.10501155e+01\n",
      "   2.10309402e+01   1.66279723e+01   7.25443018e+01   1.77452340e+01\n",
      "   1.15795158e+01   4.99343761e+01   2.28384809e+01   3.34100286e+01\n",
      "   6.02445649e+01   2.68082260e+01   4.05038849e+01   4.55097056e+01\n",
      "   6.09638438e+01   8.83403558e+00   2.79942773e+01   6.37632101e+01\n",
      "   3.38823571e+01   4.19303788e+01   3.53614873e+01   5.84163897e+00\n",
      "   9.37152581e+00   2.26425774e+01   7.53624179e+00   1.58830375e+00\n",
      "   7.40874098e+00   8.91352938e+00   5.67670481e+01   3.15646487e+01\n",
      "   1.88409530e+01   2.97533790e+00   2.57013369e+01   8.69676607e+01\n",
      "   1.13740192e+01   3.09682231e+00   1.11995316e+01   1.44935524e+01\n",
      "   3.65948879e+01   9.05946851e+00   1.80243176e+01   4.53505973e+01\n",
      "   4.19139430e+01   5.24059188e+01   1.77892739e+01   6.11265476e+00\n",
      "   6.15705309e+01   5.78428819e+00   4.70996392e+01   2.05796618e+00\n",
      "   1.72203324e+01   2.59883616e+01   1.31880166e+01   6.29891644e+01\n",
      "   1.17708068e+01   6.87302523e+00   3.32261266e+00   3.14228246e+01\n",
      "   2.40979133e+01   3.67074374e+01   6.34521265e+00   1.94595683e+00\n",
      "   8.96840824e+00   3.70723767e+00   2.40581581e+00   1.31997267e+01\n",
      "   5.72881828e+00   7.37273943e+00   6.55531264e+00   2.52547546e+00\n",
      "   2.83779588e+01   4.37881850e+00   5.84959458e+00   2.36336898e+01\n",
      "   1.80687010e+01   2.37197825e+00   2.56651371e+01   7.77274626e+00\n",
      "   2.72595326e+00   2.12897902e+01   3.37070324e+01   1.72273573e+01\n",
      "   2.48940754e+01   6.63103488e+00   1.61035545e-01   4.53701783e+00\n",
      "   1.08199063e-01   2.58940862e+01   6.28874443e-02   6.22443148e-02\n",
      "   8.11025826e-02   6.53844350e-02   6.45557641e-02   5.79377248e-02\n",
      "   7.79227940e-02   7.54706442e-02   9.43576661e-04   2.40750251e-04\n",
      "   4.55544444e-02   1.42557805e-01   1.31552615e-01   5.86825921e-02\n",
      "   1.17556638e-01   8.89872657e-02   2.89534020e-03   9.71820788e-02\n",
      "   2.44651245e-02   8.53862347e-03   1.67008479e-02   3.20771776e-03\n",
      "   1.56981807e-03   2.60514984e-02   1.54052207e-01   9.78427646e-02\n",
      "   1.92542176e-02   2.28867091e-03   7.70755513e+01   6.82408384e-02\n",
      "   5.75520929e+01   1.40888257e+01   0.00000000e+00   0.00000000e+00\n",
      "   9.44522435e-03   2.50892224e-02   6.79125738e-03   8.12044538e-03\n",
      "   6.93538691e-03   8.24447572e-02   4.55275512e-02   4.48746349e-04\n",
      "   3.53589387e-03   7.55808326e-03   1.26316914e-06   2.14110115e-02\n",
      "   9.74508785e-04   2.22094237e-07   6.44314914e-06   6.88199069e-05\n",
      "   4.02300085e-02   6.36481855e-03   1.18887970e-08   7.56335768e-07]\n",
      "(1279027, 172) (1279027, 1)\n"
     ]
    }
   ],
   "source": [
    "features = df.iloc[:, 1:].values\n",
    "labels = df.iloc[:, :1].values\n",
    "print(stats.describe(features).variance)\n",
    "print(features.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train row count : 895280, test row count : 172\n",
      "172 1\n"
     ]
    }
   ],
   "source": [
    "rnd_indices = np.random.rand(len(features)) < 0.70\n",
    "\n",
    "train_x = features[rnd_indices]\n",
    "train_y = labels[rnd_indices]\n",
    "test_x = features[~rnd_indices]\n",
    "test_y = labels[~rnd_indices]\n",
    "print(\"train row count : %d, test row count : %d\" % (train_x.shape[0], test_x.shape[1]))\n",
    "\n",
    "feature_count = train_x.shape[1]\n",
    "label_count = train_y.shape[1]\n",
    "print(feature_count, label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot Tensor(\"one_hot:0\", shape=(?, 1, 2), dtype=float32)\n",
      "reshape Tensor(\"Reshape:0\", shape=(?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "training_epochs = 100\n",
    "learning_rate = 0.01\n",
    "cost_history = np.empty(shape=[1],dtype=float)\n",
    "nb_classes = 2\n",
    "\n",
    "X = tf.placeholder(tf.float32,[None,feature_count])\n",
    "Y = tf.placeholder(tf.int32,[None,label_count])\n",
    "Y_one_hot = tf.one_hot(Y, nb_classes)  # one hot\n",
    "print(\"one_hot\", Y_one_hot)\n",
    "Y_one_hot = tf.reshape(Y_one_hot, [-1, nb_classes])\n",
    "print(\"reshape\", Y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.1)), tf.Variable(tf.random_normal([shape[1]]))\n",
    "\n",
    "def make_hidden_layer(previous_h, weight, bias, p_keep_hidden, is_dropout=True):\n",
    "    h = tf.nn.relu(tf.matmul(previous_h, weight) + bias)\n",
    "    if is_dropout:\n",
    "        h = tf.nn.dropout(h, p_keep_hidden)\n",
    "    return h\n",
    "\n",
    "def model(X, p_keep_hidden):\n",
    "    s_1 = feature_count + 2\n",
    "    s_2 = feature_count + 2\n",
    "    s_3 = feature_count\n",
    "    \n",
    "    w_h, b = init_weights([feature_count, s_1])\n",
    "    w_h2, b2 = init_weights([s_1, s_2])\n",
    "    w_h3, b3 = init_weights([s_2, s_3])\n",
    "    w_o, b_o = init_weights([s_3, nb_classes])\n",
    "    \n",
    "    h = make_hidden_layer(X, w_h, b, p_keep_hidden)\n",
    "    h2 = make_hidden_layer(h, w_h2, b2, p_keep_hidden)\n",
    "    h3 = make_hidden_layer(h2, w_h3, b3, p_keep_hidden, False)\n",
    "    \n",
    "    return tf.matmul(h3, w_o) + b_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_keep_hidden = tf.placeholder(\"float\")\n",
    "\n",
    "h0 = model(X, p_keep_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross entropy cost/loss\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=h0, labels=Y_one_hot))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = tf.argmax(h0, 1)\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(895280, 172) (895280, 1)\n",
      "(383747, 172) (383747, 1)\n",
      "(?, 172) (?, 1)\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "Step:     0\tLoss: 0.509\tAcc: 46.92%\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "Step:     4\tLoss: 0.881\tAcc: 68.30%\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "Step:     8\tLoss: 0.172\tAcc: 91.55%\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "Step:    12\tLoss: 0.536\tAcc: 78.19%\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "Step:    16\tLoss: 0.403\tAcc: 86.01%\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "Step:    20\tLoss: 0.083\tAcc: 98.08%\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "Step:    24\tLoss: 0.125\tAcc: 96.29%\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "Step:    28\tLoss: 0.017\tAcc: 99.69%\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "Step:    32\tLoss: 0.017\tAcc: 99.73%\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "Step:    36\tLoss: 0.012\tAcc: 99.78%\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "Step:    40\tLoss: 0.284\tAcc: 97.54%\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "Step:    44\tLoss: 0.009\tAcc: 99.84%\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "Step:    48\tLoss: 0.027\tAcc: 99.64%\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "Step:    52\tLoss: 0.008\tAcc: 99.90%\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "Step:    56\tLoss: 0.003\tAcc: 99.97%\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "Step:    60\tLoss: 0.001\tAcc: 99.98%\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "Step:    64\tLoss: 0.002\tAcc: 99.97%\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "Step:    68\tLoss: 0.002\tAcc: 99.98%\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "Step:    72\tLoss: 0.003\tAcc: 99.96%\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "Step:    76\tLoss: 0.005\tAcc: 99.93%\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "Step:    80\tLoss: 0.060\tAcc: 99.16%\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "Step:    84\tLoss: 0.002\tAcc: 99.98%\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:    88\tLoss: 0.002\tAcc: 99.97%\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "Step:    92\tLoss: 0.001\tAcc: 99.98%\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "Step:    96\tLoss: 0.001\tAcc: 99.99%\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "batch num : 0 / 446, index: 0 ~ 2000\n",
      "batch num : 200 / 446, index: 400000 ~ 402000\n",
      "batch num : 400 / 446, index: 800000 ~ 802000\n",
      "batch num : 446 / 446, index: 892000 ~ 895279\n",
      "Step:   100\tLoss: 0.006\tAcc: 99.99%\n",
      "(383747,)\n",
      "Test Accuracy: 0.999918\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape, train_y.shape)\n",
    "print(test_x.shape, test_y.shape)\n",
    "print(X.shape, Y.shape)\n",
    "training_dropout_h = 0.95\n",
    "\n",
    "batch_size = 2000\n",
    "batch_length = int(train_x.shape[0] / batch_size)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(training_epochs + 1):\n",
    "        for batch_num in range(batch_length):\n",
    "            start_idx = batch_num * batch_size\n",
    "            end_idx = (train_x.shape[0] - 1) if batch_num == batch_length - 1 else (batch_num + 1) * batch_size\n",
    "                \n",
    "            if batch_num % 200 == 0 or batch_num == batch_length - 1:\n",
    "                print(\"batch num : %d / %d, index: %d ~ %d\" % (batch_num, batch_length - 1, start_idx, end_idx))\n",
    "            \n",
    "            sess.run(optimizer, feed_dict={X: train_x[start_idx:end_idx], Y: train_y[start_idx:end_idx], p_keep_hidden: training_dropout_h})\n",
    "\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict={\n",
    "                                 X: train_x, Y: train_y, p_keep_input: training_dropout_i, p_keep_hidden: training_dropout_h})\n",
    "        cost_history = np.append(cost_history, acc)\n",
    "        if step % 4 == 0:\n",
    "            print(\"Step: {:5}\\tLoss: {:.3f}\\tAcc: {:.2%}\".format(\n",
    "                step, loss, acc))\n",
    "            \n",
    "    # Test model and check accuracy\n",
    "    pre = tf.argmax(h0, 1)\n",
    "    test_yy = np.transpose(test_y.ravel())\n",
    "    print(test_yy.shape)\n",
    "    correct_prediction = tf.equal(pre, test_yy)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print('Test Accuracy:', sess.run(accuracy, feed_dict={X: test_x, p_keep_hidden: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nALKh5AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21bffc8efd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(cost_history.shape)\n",
    "plt.plot(range(len(cost_history)),cost_history)\n",
    "plt.axis([0,training_epochs,0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing time : 272 seconds\n"
     ]
    }
   ],
   "source": [
    "sess.close()\n",
    "end_time = time.time()\n",
    "print(\"processing time : %d seconds\" % (end_time - start_time,))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
