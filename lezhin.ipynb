{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from numpy import genfromtxt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    "    df = pd.read_csv(file_name, sep='\\t', header=None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deera\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2821: DtypeWarning: Columns (7,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "df = read_data('lezhin_public_dataset_training.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.iloc[:, :20]\n",
    "del df[7], df[8], df[16], df[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.169985e-01</td>\n",
       "      <td>1.327282e-01</td>\n",
       "      <td>2.840949e-01</td>\n",
       "      <td>1.115090e-01</td>\n",
       "      <td>2.589148e-01</td>\n",
       "      <td>2.636578e+00</td>\n",
       "      <td>7.994948e+01</td>\n",
       "      <td>-5.841105e+14</td>\n",
       "      <td>1.291841e-02</td>\n",
       "      <td>1.485504e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.166512e-05</td>\n",
       "      <td>6.843252e-02</td>\n",
       "      <td>5.184376e-03</td>\n",
       "      <td>2.199250e-06</td>\n",
       "      <td>3.106541e-05</td>\n",
       "      <td>2.997524e-04</td>\n",
       "      <td>1.249980e-01</td>\n",
       "      <td>3.696069e-02</td>\n",
       "      <td>4.047608e-07</td>\n",
       "      <td>4.232123e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.122018e-01</td>\n",
       "      <td>3.392809e-01</td>\n",
       "      <td>4.509824e-01</td>\n",
       "      <td>3.147615e-01</td>\n",
       "      <td>4.380389e-01</td>\n",
       "      <td>6.181888e+00</td>\n",
       "      <td>1.290465e+02</td>\n",
       "      <td>7.339708e+16</td>\n",
       "      <td>1.129227e-01</td>\n",
       "      <td>3.854197e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>1.123908e-03</td>\n",
       "      <td>1.463250e-01</td>\n",
       "      <td>3.121712e-02</td>\n",
       "      <td>4.712688e-04</td>\n",
       "      <td>2.538336e-03</td>\n",
       "      <td>8.295776e-03</td>\n",
       "      <td>2.005742e-01</td>\n",
       "      <td>7.977981e-02</td>\n",
       "      <td>1.090358e-04</td>\n",
       "      <td>8.696757e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.940000e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.060000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.560000e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.504000e-01</td>\n",
       "      <td>2.880000e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>6.574000e+03</td>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.883000e-01</td>\n",
       "      <td>8.586000e-01</td>\n",
       "      <td>9.111000e-01</td>\n",
       "      <td>4.424000e-01</td>\n",
       "      <td>5.783000e-01</td>\n",
       "      <td>8.418000e-01</td>\n",
       "      <td>9.545000e-01</td>\n",
       "      <td>7.078000e-01</td>\n",
       "      <td>1.044000e-01</td>\n",
       "      <td>4.217000e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 173 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2             3             4    \\\n",
       "count  1.279027e+06  1.279027e+06  1.279027e+06  1.279027e+06  1.279027e+06   \n",
       "mean   2.169985e-01  1.327282e-01  2.840949e-01  1.115090e-01  2.589148e-01   \n",
       "std    4.122018e-01  3.392809e-01  4.509824e-01  3.147615e-01  4.380389e-01   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    0.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00  1.000000e+00   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "                5             6             9             10            11   \\\n",
       "count  1.279027e+06  1.279027e+06  1.279027e+06  1.279027e+06  1.279027e+06   \n",
       "mean   2.636578e+00  7.994948e+01 -5.841105e+14  1.291841e-02  1.485504e-05   \n",
       "std    6.181888e+00  1.290465e+02  7.339708e+16  1.129227e-01  3.854197e-03   \n",
       "min    0.000000e+00  0.000000e+00 -9.223372e+18  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  3.000000e+01  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    0.000000e+00  1.060000e+02  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max    2.300000e+01  6.574000e+03  1.900000e+01  1.000000e+00  1.000000e+00   \n",
       "\n",
       "           ...                167           168           169           170  \\\n",
       "count      ...       1.279027e+06  1.279027e+06  1.279027e+06  1.279027e+06   \n",
       "mean       ...       1.166512e-05  6.843252e-02  5.184376e-03  2.199250e-06   \n",
       "std        ...       1.123908e-03  1.463250e-01  3.121712e-02  4.712688e-04   \n",
       "min        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%        ...       0.000000e+00  4.560000e-02  0.000000e+00  0.000000e+00   \n",
       "max        ...       3.883000e-01  8.586000e-01  9.111000e-01  4.424000e-01   \n",
       "\n",
       "                171           172           173           174           175  \\\n",
       "count  1.279027e+06  1.279027e+06  1.279027e+06  1.279027e+06  1.279027e+06   \n",
       "mean   3.106541e-05  2.997524e-04  1.249980e-01  3.696069e-02  4.047608e-07   \n",
       "std    2.538336e-03  8.295776e-03  2.005742e-01  7.977981e-02  1.090358e-04   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00  2.940000e-02  0.000000e+00  0.000000e+00   \n",
       "75%    0.000000e+00  0.000000e+00  1.504000e-01  2.880000e-02  0.000000e+00   \n",
       "max    5.783000e-01  8.418000e-01  9.545000e-01  7.078000e-01  1.044000e-01   \n",
       "\n",
       "                176  \n",
       "count  1.279027e+06  \n",
       "mean   4.232123e-06  \n",
       "std    8.696757e-04  \n",
       "min    0.000000e+00  \n",
       "25%    0.000000e+00  \n",
       "50%    0.000000e+00  \n",
       "75%    0.000000e+00  \n",
       "max    4.217000e-01  \n",
       "\n",
       "[8 rows x 173 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.15111543e-01   2.03385131e-01   9.90748072e-02   1.91878069e-01\n",
      "   3.82157440e+01   1.66529942e+04   5.38713173e+33   1.27515383e-02\n",
      "   1.48548331e-05   4.08220688e-02   1.02018734e-01   4.10086862e-02\n",
      "   3.25354759e-03   2.45624487e-01   4.74883876e+01   4.61867511e+01\n",
      "   6.06847586e+01   6.37896923e+01   3.75022068e+01   3.60551168e+01\n",
      "   4.33698589e+01   9.70587381e+01   1.86694818e+01   7.72218115e+01\n",
      "   2.60344947e+01   1.45445092e+01   1.19066626e+01   3.46125399e+01\n",
      "   6.31201610e+01   3.17641667e+01   7.50052257e+01   1.10501155e+01\n",
      "   2.10309402e+01   1.66279723e+01   7.25443018e+01   1.77452340e+01\n",
      "   1.15795158e+01   4.99343761e+01   2.28384809e+01   3.34100286e+01\n",
      "   6.02445649e+01   2.68082260e+01   4.05038849e+01   4.55097056e+01\n",
      "   6.09638438e+01   8.83403558e+00   2.79942773e+01   6.37632101e+01\n",
      "   3.38823571e+01   4.19303788e+01   3.53614873e+01   5.84163897e+00\n",
      "   9.37152581e+00   2.26425774e+01   7.53624179e+00   1.58830375e+00\n",
      "   7.40874098e+00   8.91352938e+00   5.67670481e+01   3.15646487e+01\n",
      "   1.88409530e+01   2.97533790e+00   2.57013369e+01   8.69676607e+01\n",
      "   1.13740192e+01   3.09682231e+00   1.11995316e+01   1.44935524e+01\n",
      "   3.65948879e+01   9.05946851e+00   1.80243176e+01   4.53505973e+01\n",
      "   4.19139430e+01   5.24059188e+01   1.77892739e+01   6.11265476e+00\n",
      "   6.15705309e+01   5.78428819e+00   4.70996392e+01   2.05796618e+00\n",
      "   1.72203324e+01   2.59883616e+01   1.31880166e+01   6.29891644e+01\n",
      "   1.17708068e+01   6.87302523e+00   3.32261266e+00   3.14228246e+01\n",
      "   2.40979133e+01   3.67074374e+01   6.34521265e+00   1.94595683e+00\n",
      "   8.96840824e+00   3.70723767e+00   2.40581581e+00   1.31997267e+01\n",
      "   5.72881828e+00   7.37273943e+00   6.55531264e+00   2.52547546e+00\n",
      "   2.83779588e+01   4.37881850e+00   5.84959458e+00   2.36336898e+01\n",
      "   1.80687010e+01   2.37197825e+00   2.56651371e+01   7.77274626e+00\n",
      "   2.72595326e+00   2.12897902e+01   3.37070324e+01   1.72273573e+01\n",
      "   2.48940754e+01   6.63103488e+00   1.61035545e-01   4.53701783e+00\n",
      "   1.08199063e-01   2.58940862e+01   6.28874443e-02   6.22443148e-02\n",
      "   8.11025826e-02   6.53844350e-02   6.45557641e-02   5.79377248e-02\n",
      "   7.79227940e-02   7.54706442e-02   9.43576661e-04   2.40750251e-04\n",
      "   4.55544444e-02   1.42557805e-01   1.31552615e-01   5.86825921e-02\n",
      "   1.17556638e-01   8.89872657e-02   2.89534020e-03   9.71820788e-02\n",
      "   2.44651245e-02   8.53862347e-03   1.67008479e-02   3.20771776e-03\n",
      "   1.56981807e-03   2.60514984e-02   1.54052207e-01   9.78427646e-02\n",
      "   1.92542176e-02   2.28867091e-03   7.70755513e+01   6.82408384e-02\n",
      "   5.75520929e+01   1.40888257e+01   0.00000000e+00   0.00000000e+00\n",
      "   9.44522435e-03   2.50892224e-02   6.79125738e-03   8.12044538e-03\n",
      "   6.93538691e-03   8.24447572e-02   4.55275512e-02   4.48746349e-04\n",
      "   3.53589387e-03   7.55808326e-03   1.26316914e-06   2.14110115e-02\n",
      "   9.74508785e-04   2.22094237e-07   6.44314914e-06   6.88199069e-05\n",
      "   4.02300085e-02   6.36481855e-03   1.18887970e-08   7.56335768e-07]\n",
      "(1279027, 172) (1279027, 1)\n"
     ]
    }
   ],
   "source": [
    "features = df.iloc[:, 1:].values\n",
    "labels = df.iloc[:, :1].values\n",
    "print(stats.describe(features).variance)\n",
    "print(features.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train row count : 896173, test row count : 172\n",
      "172 1\n"
     ]
    }
   ],
   "source": [
    "rnd_indices = np.random.rand(len(features)) < 0.70\n",
    "\n",
    "train_x = features[rnd_indices]\n",
    "train_y = labels[rnd_indices]\n",
    "test_x = features[~rnd_indices]\n",
    "test_y = labels[~rnd_indices]\n",
    "print(\"train row count : %d, test row count : %d\" % (train_x.shape[0], test_x.shape[1]))\n",
    "\n",
    "feature_count = train_x.shape[1]\n",
    "label_count = train_y.shape[1]\n",
    "print(feature_count, label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot Tensor(\"one_hot:0\", shape=(?, 1, 2), dtype=float32)\n",
      "reshape Tensor(\"Reshape:0\", shape=(?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "training_epochs = 100\n",
    "learning_rate = 0.01\n",
    "cost_history = np.empty(shape=[1],dtype=float)\n",
    "nb_classes = 2\n",
    "\n",
    "X = tf.placeholder(tf.float32,[None,feature_count])\n",
    "Y = tf.placeholder(tf.int32,[None,label_count])\n",
    "Y_one_hot = tf.one_hot(Y, nb_classes)  # one hot\n",
    "print(\"one_hot\", Y_one_hot)\n",
    "Y_one_hot = tf.reshape(Y_one_hot, [-1, nb_classes])\n",
    "print(\"reshape\", Y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.1)), tf.Variable(tf.random_normal([shape[1]]))\n",
    "\n",
    "def make_hidden_layer(previous_h, weight, bias, p_keep_hidden, is_dropout=True):\n",
    "    h = tf.nn.relu(tf.matmul(previous_h, weight) + bias)\n",
    "    if is_dropout:\n",
    "        h = tf.nn.dropout(h, p_keep_hidden)\n",
    "    return h\n",
    "\n",
    "def model(X, p_keep_input, p_keep_hidden):\n",
    "    s_1 = feature_count + 2\n",
    "    s_2 = feature_count + 2\n",
    "    s_3 = feature_count\n",
    "    \n",
    "    w_h, b = init_weights([feature_count, s_1])\n",
    "    w_h2, b2 = init_weights([s_1, s_2])\n",
    "    w_h3, b3 = init_weights([s_2, s_3])\n",
    "    w_o, b_o = init_weights([s_3, nb_classes])\n",
    "    \n",
    "    h = make_hidden_layer(X, w_h, b, p_keep_hidden)\n",
    "    h2 = make_hidden_layer(h, w_h2, b2, p_keep_hidden)\n",
    "    h3 = make_hidden_layer(h2, w_h3, b3, p_keep_hidden, False)\n",
    "    \n",
    "    return tf.matmul(h3, w_o) + b_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_keep_input = tf.placeholder(\"float\")\n",
    "p_keep_hidden = tf.placeholder(\"float\")\n",
    "\n",
    "h0 = model(X, p_keep_input, p_keep_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross entropy cost/loss\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=h0, labels=Y_one_hot))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = tf.argmax(h0, 1)\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(896173, 172) (896173, 1)\n",
      "(382854, 172) (382854, 1)\n",
      "(?, 172) (?, 1)\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "Step:     0\tLoss: 1.958\tAcc: 45.55%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "Step:     4\tLoss: 116351819776.000\tAcc: 89.25%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "Step:     8\tLoss: 0.116\tAcc: 96.85%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "Step:    12\tLoss: 0.026\tAcc: 99.55%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "Step:    16\tLoss: 44189425664.000\tAcc: 81.71%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "Step:    20\tLoss: 0.301\tAcc: 89.90%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "Step:    24\tLoss: 0.236\tAcc: 92.37%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "Step:    28\tLoss: 0.075\tAcc: 98.54%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "Step:    32\tLoss: 0.017\tAcc: 99.75%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "Step:    36\tLoss: 3.644\tAcc: 80.79%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "Step:    40\tLoss: 0.012\tAcc: 99.81%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "Step:    44\tLoss: 0.016\tAcc: 99.73%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "Step:    48\tLoss: 0.012\tAcc: 99.81%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "Step:    52\tLoss: 0.012\tAcc: 99.81%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "Step:    56\tLoss: 0.014\tAcc: 99.76%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "Step:    60\tLoss: 0.004\tAcc: 99.94%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "Step:    64\tLoss: 0.002\tAcc: 99.98%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "Step:    68\tLoss: 0.002\tAcc: 99.98%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "Step:    72\tLoss: 0.001\tAcc: 99.99%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "Step:    76\tLoss: 0.002\tAcc: 99.97%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "Step:    80\tLoss: 0.002\tAcc: 99.98%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "Step:    84\tLoss: 0.002\tAcc: 99.98%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:    88\tLoss: 0.003\tAcc: 99.97%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "Step:    92\tLoss: 0.002\tAcc: 99.98%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "Step:    96\tLoss: 0.001\tAcc: 99.99%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896172\n",
      "Step:   100\tLoss: 0.002\tAcc: 99.98%\n",
      "(382854,)\n",
      "Test Accuracy: 0.999922\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape, train_y.shape)\n",
    "print(test_x.shape, test_y.shape)\n",
    "print(X.shape, Y.shape)\n",
    "training_dropout_i = 0.95\n",
    "training_dropout_h = 0.95\n",
    "\n",
    "batch_size = 2000\n",
    "batch_length = int(train_x.shape[0] / batch_size)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(training_epochs + 1):\n",
    "        for batch_num in range(batch_length):\n",
    "            start_idx = batch_num * batch_size\n",
    "            end_idx = (train_x.shape[0] - 1) if batch_num == batch_length - 1 else (batch_num + 1) * batch_size\n",
    "                \n",
    "            if batch_num % 200 == 0 or batch_num == batch_length - 1:\n",
    "                print(\"batch num : %d / %d, index: %d ~ %d\" % (batch_num, batch_length - 1, start_idx, end_idx))\n",
    "            \n",
    "            sess.run(optimizer, feed_dict={X: train_x[start_idx:end_idx], Y: train_y[start_idx:end_idx], p_keep_input: training_dropout_i, p_keep_hidden: training_dropout_h})\n",
    "\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict={\n",
    "                                 X: train_x, Y: train_y, p_keep_input: training_dropout_i, p_keep_hidden: training_dropout_h})\n",
    "        cost_history = np.append(cost_history, acc)\n",
    "        if step % 4 == 0:\n",
    "            print(\"Step: {:5}\\tLoss: {:.3f}\\tAcc: {:.2%}\".format(\n",
    "                step, loss, acc))\n",
    "            \n",
    "    # Test model and check accuracy\n",
    "    pre = tf.argmax(h0, 1)\n",
    "    test_yy = np.transpose(test_y.ravel())\n",
    "    print(test_yy.shape)\n",
    "    correct_prediction = tf.equal(pre, test_yy)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print('Test Accuracy:', sess.run(accuracy, feed_dict={X: test_x, \n",
    "                                                         p_keep_input: 1.0,\n",
    "                                                         p_keep_hidden: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRJqIQl9EpIko9EVEmsj/Bw9MF/psdJHLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2d7e4dcf6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(cost_history.shape)\n",
    "plt.plot(range(len(cost_history)),cost_history)\n",
    "plt.axis([0,training_epochs,0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
