{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from numpy import genfromtxt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    "    df = pd.read_csv(file_name, sep='\\t', header=None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deera\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2821: DtypeWarning: Columns (7,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "df = read_data('lezhin_public_dataset_training.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.iloc[:, :20]\n",
    "del df[7], df[8], df[16], df[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "      <td>1.279027e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.169985e-01</td>\n",
       "      <td>1.327282e-01</td>\n",
       "      <td>2.840949e-01</td>\n",
       "      <td>1.115090e-01</td>\n",
       "      <td>2.589148e-01</td>\n",
       "      <td>2.636578e+00</td>\n",
       "      <td>7.994948e+01</td>\n",
       "      <td>-5.841105e+14</td>\n",
       "      <td>1.291841e-02</td>\n",
       "      <td>1.485504e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.166512e-05</td>\n",
       "      <td>6.843252e-02</td>\n",
       "      <td>5.184376e-03</td>\n",
       "      <td>2.199250e-06</td>\n",
       "      <td>3.106541e-05</td>\n",
       "      <td>2.997524e-04</td>\n",
       "      <td>1.249980e-01</td>\n",
       "      <td>3.696069e-02</td>\n",
       "      <td>4.047608e-07</td>\n",
       "      <td>4.232123e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.122018e-01</td>\n",
       "      <td>3.392809e-01</td>\n",
       "      <td>4.509824e-01</td>\n",
       "      <td>3.147615e-01</td>\n",
       "      <td>4.380389e-01</td>\n",
       "      <td>6.181888e+00</td>\n",
       "      <td>1.290465e+02</td>\n",
       "      <td>7.339708e+16</td>\n",
       "      <td>1.129227e-01</td>\n",
       "      <td>3.854197e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>1.123908e-03</td>\n",
       "      <td>1.463250e-01</td>\n",
       "      <td>3.121712e-02</td>\n",
       "      <td>4.712688e-04</td>\n",
       "      <td>2.538336e-03</td>\n",
       "      <td>8.295776e-03</td>\n",
       "      <td>2.005742e-01</td>\n",
       "      <td>7.977981e-02</td>\n",
       "      <td>1.090358e-04</td>\n",
       "      <td>8.696757e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.940000e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.060000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.560000e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.504000e-01</td>\n",
       "      <td>2.880000e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>6.574000e+03</td>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.883000e-01</td>\n",
       "      <td>8.586000e-01</td>\n",
       "      <td>9.111000e-01</td>\n",
       "      <td>4.424000e-01</td>\n",
       "      <td>5.783000e-01</td>\n",
       "      <td>8.418000e-01</td>\n",
       "      <td>9.545000e-01</td>\n",
       "      <td>7.078000e-01</td>\n",
       "      <td>1.044000e-01</td>\n",
       "      <td>4.217000e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 173 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2             3             4    \\\n",
       "count  1.279027e+06  1.279027e+06  1.279027e+06  1.279027e+06  1.279027e+06   \n",
       "mean   2.169985e-01  1.327282e-01  2.840949e-01  1.115090e-01  2.589148e-01   \n",
       "std    4.122018e-01  3.392809e-01  4.509824e-01  3.147615e-01  4.380389e-01   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    0.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00  1.000000e+00   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "                5             6             9             10            11   \\\n",
       "count  1.279027e+06  1.279027e+06  1.279027e+06  1.279027e+06  1.279027e+06   \n",
       "mean   2.636578e+00  7.994948e+01 -5.841105e+14  1.291841e-02  1.485504e-05   \n",
       "std    6.181888e+00  1.290465e+02  7.339708e+16  1.129227e-01  3.854197e-03   \n",
       "min    0.000000e+00  0.000000e+00 -9.223372e+18  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  3.000000e+01  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    0.000000e+00  1.060000e+02  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max    2.300000e+01  6.574000e+03  1.900000e+01  1.000000e+00  1.000000e+00   \n",
       "\n",
       "           ...                167           168           169           170  \\\n",
       "count      ...       1.279027e+06  1.279027e+06  1.279027e+06  1.279027e+06   \n",
       "mean       ...       1.166512e-05  6.843252e-02  5.184376e-03  2.199250e-06   \n",
       "std        ...       1.123908e-03  1.463250e-01  3.121712e-02  4.712688e-04   \n",
       "min        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%        ...       0.000000e+00  4.560000e-02  0.000000e+00  0.000000e+00   \n",
       "max        ...       3.883000e-01  8.586000e-01  9.111000e-01  4.424000e-01   \n",
       "\n",
       "                171           172           173           174           175  \\\n",
       "count  1.279027e+06  1.279027e+06  1.279027e+06  1.279027e+06  1.279027e+06   \n",
       "mean   3.106541e-05  2.997524e-04  1.249980e-01  3.696069e-02  4.047608e-07   \n",
       "std    2.538336e-03  8.295776e-03  2.005742e-01  7.977981e-02  1.090358e-04   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00  2.940000e-02  0.000000e+00  0.000000e+00   \n",
       "75%    0.000000e+00  0.000000e+00  1.504000e-01  2.880000e-02  0.000000e+00   \n",
       "max    5.783000e-01  8.418000e-01  9.545000e-01  7.078000e-01  1.044000e-01   \n",
       "\n",
       "                176  \n",
       "count  1.279027e+06  \n",
       "mean   4.232123e-06  \n",
       "std    8.696757e-04  \n",
       "min    0.000000e+00  \n",
       "25%    0.000000e+00  \n",
       "50%    0.000000e+00  \n",
       "75%    0.000000e+00  \n",
       "max    4.217000e-01  \n",
       "\n",
       "[8 rows x 173 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.15111543e-01   2.03385131e-01   9.90748072e-02   1.91878069e-01\n",
      "   3.82157440e+01   1.66529942e+04   5.38713173e+33   1.27515383e-02\n",
      "   1.48548331e-05   4.08220688e-02   1.02018734e-01   4.10086862e-02\n",
      "   3.25354759e-03   2.45624487e-01   4.74883876e+01   4.61867511e+01\n",
      "   6.06847586e+01   6.37896923e+01   3.75022068e+01   3.60551168e+01\n",
      "   4.33698589e+01   9.70587381e+01   1.86694818e+01   7.72218115e+01\n",
      "   2.60344947e+01   1.45445092e+01   1.19066626e+01   3.46125399e+01\n",
      "   6.31201610e+01   3.17641667e+01   7.50052257e+01   1.10501155e+01\n",
      "   2.10309402e+01   1.66279723e+01   7.25443018e+01   1.77452340e+01\n",
      "   1.15795158e+01   4.99343761e+01   2.28384809e+01   3.34100286e+01\n",
      "   6.02445649e+01   2.68082260e+01   4.05038849e+01   4.55097056e+01\n",
      "   6.09638438e+01   8.83403558e+00   2.79942773e+01   6.37632101e+01\n",
      "   3.38823571e+01   4.19303788e+01   3.53614873e+01   5.84163897e+00\n",
      "   9.37152581e+00   2.26425774e+01   7.53624179e+00   1.58830375e+00\n",
      "   7.40874098e+00   8.91352938e+00   5.67670481e+01   3.15646487e+01\n",
      "   1.88409530e+01   2.97533790e+00   2.57013369e+01   8.69676607e+01\n",
      "   1.13740192e+01   3.09682231e+00   1.11995316e+01   1.44935524e+01\n",
      "   3.65948879e+01   9.05946851e+00   1.80243176e+01   4.53505973e+01\n",
      "   4.19139430e+01   5.24059188e+01   1.77892739e+01   6.11265476e+00\n",
      "   6.15705309e+01   5.78428819e+00   4.70996392e+01   2.05796618e+00\n",
      "   1.72203324e+01   2.59883616e+01   1.31880166e+01   6.29891644e+01\n",
      "   1.17708068e+01   6.87302523e+00   3.32261266e+00   3.14228246e+01\n",
      "   2.40979133e+01   3.67074374e+01   6.34521265e+00   1.94595683e+00\n",
      "   8.96840824e+00   3.70723767e+00   2.40581581e+00   1.31997267e+01\n",
      "   5.72881828e+00   7.37273943e+00   6.55531264e+00   2.52547546e+00\n",
      "   2.83779588e+01   4.37881850e+00   5.84959458e+00   2.36336898e+01\n",
      "   1.80687010e+01   2.37197825e+00   2.56651371e+01   7.77274626e+00\n",
      "   2.72595326e+00   2.12897902e+01   3.37070324e+01   1.72273573e+01\n",
      "   2.48940754e+01   6.63103488e+00   1.61035545e-01   4.53701783e+00\n",
      "   1.08199063e-01   2.58940862e+01   6.28874443e-02   6.22443148e-02\n",
      "   8.11025826e-02   6.53844350e-02   6.45557641e-02   5.79377248e-02\n",
      "   7.79227940e-02   7.54706442e-02   9.43576661e-04   2.40750251e-04\n",
      "   4.55544444e-02   1.42557805e-01   1.31552615e-01   5.86825921e-02\n",
      "   1.17556638e-01   8.89872657e-02   2.89534020e-03   9.71820788e-02\n",
      "   2.44651245e-02   8.53862347e-03   1.67008479e-02   3.20771776e-03\n",
      "   1.56981807e-03   2.60514984e-02   1.54052207e-01   9.78427646e-02\n",
      "   1.92542176e-02   2.28867091e-03   7.70755513e+01   6.82408384e-02\n",
      "   5.75520929e+01   1.40888257e+01   0.00000000e+00   0.00000000e+00\n",
      "   9.44522435e-03   2.50892224e-02   6.79125738e-03   8.12044538e-03\n",
      "   6.93538691e-03   8.24447572e-02   4.55275512e-02   4.48746349e-04\n",
      "   3.53589387e-03   7.55808326e-03   1.26316914e-06   2.14110115e-02\n",
      "   9.74508785e-04   2.22094237e-07   6.44314914e-06   6.88199069e-05\n",
      "   4.02300085e-02   6.36481855e-03   1.18887970e-08   7.56335768e-07]\n",
      "(1279027, 172) (1279027, 1)\n"
     ]
    }
   ],
   "source": [
    "features = df.iloc[:, 1:].values\n",
    "labels = df.iloc[:, :1].values\n",
    "print(stats.describe(features).variance)\n",
    "print(features.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train row count : 896439, test row count : 382588\n",
      "172 1\n"
     ]
    }
   ],
   "source": [
    "rnd_indices = np.random.rand(len(features)) < 0.70\n",
    "\n",
    "train_x = features[rnd_indices]\n",
    "train_y = labels[rnd_indices]\n",
    "test_x = features[~rnd_indices]\n",
    "test_y = labels[~rnd_indices]\n",
    "print(\"train row count : %d, test row count : %d\" % (train_x.shape[0], test_x.shape[0]))\n",
    "\n",
    "feature_count = train_x.shape[1]\n",
    "label_count = train_y.shape[1]\n",
    "print(feature_count, label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot Tensor(\"one_hot:0\", shape=(?, 1, 2), dtype=float32)\n",
      "reshape Tensor(\"Reshape:0\", shape=(?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "training_epochs = 90\n",
    "learning_rate = 0.01\n",
    "cost_history = np.empty(shape=[1],dtype=float)\n",
    "nb_classes = 2\n",
    "\n",
    "X = tf.placeholder(tf.float32,[None,feature_count])\n",
    "Y = tf.placeholder(tf.int32,[None,label_count])\n",
    "Y_one_hot = tf.one_hot(Y, nb_classes)  # one hot\n",
    "print(\"one_hot\", Y_one_hot)\n",
    "Y_one_hot = tf.reshape(Y_one_hot, [-1, nb_classes])\n",
    "print(\"reshape\", Y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.1)), tf.Variable(tf.random_normal([shape[1]]))\n",
    "\n",
    "def make_hidden_layer(previous_h, weight, bias, p_keep_hidden, is_dropout=True):\n",
    "    h = tf.nn.relu(tf.matmul(previous_h, weight) + bias)\n",
    "    if is_dropout:\n",
    "        h = tf.nn.dropout(h, p_keep_hidden)\n",
    "    return h\n",
    "\n",
    "def model(X, p_keep_hidden):\n",
    "    s_1 = feature_count + 2\n",
    "    s_2 = feature_count + 2\n",
    "    s_3 = feature_count\n",
    "    \n",
    "    w_h, b = init_weights([feature_count, s_1])\n",
    "    w_h2, b2 = init_weights([s_1, s_2])\n",
    "    w_h3, b3 = init_weights([s_2, s_3])\n",
    "    w_o, b_o = init_weights([s_3, nb_classes])\n",
    "    \n",
    "    h = make_hidden_layer(X, w_h, b, p_keep_hidden)\n",
    "    h2 = make_hidden_layer(h, w_h2, b2, p_keep_hidden)\n",
    "    h3 = make_hidden_layer(h2, w_h3, b3, p_keep_hidden, False)\n",
    "    \n",
    "    return tf.matmul(h3, w_o) + b_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_keep_hidden = tf.placeholder(\"float\")\n",
    "\n",
    "h0 = model(X, p_keep_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross entropy cost/loss\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=h0, labels=Y_one_hot))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = tf.argmax(h0, 1)\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(896439, 172) (896439, 1)\n",
      "(382588, 172) (382588, 1)\n",
      "(?, 172) (?, 1)\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "Step:     0\tLoss: 1.465\tAcc: 51.58%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "Step:     4\tLoss: 0.354\tAcc: 88.22%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "Step:     8\tLoss: 0.360\tAcc: 88.03%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "Step:    12\tLoss: 0.114\tAcc: 97.67%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "Step:    16\tLoss: 0.360\tAcc: 88.91%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "Step:    20\tLoss: 0.215\tAcc: 93.16%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "Step:    24\tLoss: 0.207\tAcc: 94.57%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "Step:    28\tLoss: 0.219\tAcc: 93.82%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "Step:    32\tLoss: 0.065\tAcc: 98.10%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "Step:    36\tLoss: 0.033\tAcc: 98.91%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "Step:    40\tLoss: 0.026\tAcc: 99.07%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "Step:    44\tLoss: 0.024\tAcc: 99.29%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "Step:    48\tLoss: 0.021\tAcc: 99.27%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "Step:    52\tLoss: 0.022\tAcc: 99.24%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "Step:    56\tLoss: 0.019\tAcc: 99.47%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "Step:    60\tLoss: 0.014\tAcc: 99.59%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "Step:    64\tLoss: 0.007\tAcc: 99.85%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "Step:    68\tLoss: 0.006\tAcc: 99.89%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "Step:    72\tLoss: 0.008\tAcc: 99.86%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "Step:    76\tLoss: 0.009\tAcc: 99.82%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "Step:    80\tLoss: 0.010\tAcc: 99.84%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "Step:    84\tLoss: 0.004\tAcc: 99.91%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:    88\tLoss: 0.005\tAcc: 99.88%\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "batch num : 0 / 447, index: 0 ~ 2000\n",
      "batch num : 200 / 447, index: 400000 ~ 402000\n",
      "batch num : 400 / 447, index: 800000 ~ 802000\n",
      "batch num : 447 / 447, index: 894000 ~ 896438\n",
      "(382588,)\n",
      "Test Accuracy: 0.999856\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape, train_y.shape)\n",
    "print(test_x.shape, test_y.shape)\n",
    "print(X.shape, Y.shape)\n",
    "training_dropout_h = 0.95\n",
    "\n",
    "batch_size = 2000\n",
    "batch_length = int(train_x.shape[0] / batch_size)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(training_epochs + 1):\n",
    "        for batch_num in range(batch_length):\n",
    "            start_idx = batch_num * batch_size\n",
    "            end_idx = (train_x.shape[0] - 1) if batch_num == batch_length - 1 else (batch_num + 1) * batch_size\n",
    "                \n",
    "            if batch_num % 200 == 0 or batch_num == batch_length - 1:\n",
    "                print(\"batch num : %d / %d, index: %d ~ %d\" % (batch_num, batch_length - 1, start_idx, end_idx))\n",
    "            \n",
    "            sess.run(optimizer, feed_dict={X: train_x[start_idx:end_idx], Y: train_y[start_idx:end_idx], p_keep_hidden: training_dropout_h})\n",
    "\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict={\n",
    "                                 X: train_x, Y: train_y, p_keep_hidden: training_dropout_h})\n",
    "        cost_history = np.append(cost_history, acc)\n",
    "        if step % 4 == 0:\n",
    "            print(\"Step: {:5}\\tLoss: {:.3f}\\tAcc: {:.2%}\".format(\n",
    "                step, loss, acc))\n",
    "            \n",
    "    # Test model and check accuracy\n",
    "    pre = tf.argmax(h0, 1)\n",
    "    test_yy = np.transpose(test_y.ravel())\n",
    "    print(test_yy.shape)\n",
    "    correct_prediction = tf.equal(pre, test_yy)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print('Test Accuracy:', sess.run(accuracy, feed_dict={X: test_x, p_keep_hidden: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8XNV99/HPb2ak0TKSrNWbvG9gDGYRBgIhLIGYkIYm\nDQ0kaZqlofQVsjRptqdt+uRJ0zbN8iRkozyEpNAUEhKaUEogBEjYQoIMxni38CbJsrXv2yzn+WNG\nsixrGctjXen6+3699JLm3quZ34yk7xyde8655pxDRET8K+B1ASIicmop6EVEfE5BLyLicwp6ERGf\nU9CLiPicgl5ExOcmDXozu9vMGs1s6zj7zcxuN7MaM9tiZudnvkwREZmqdFr0PwQ2TrD/OmBV6uMW\n4HsnX5aIiGTKpEHvnHsaaJ3gkBuAe1zSC8AcM5ufqQJFROTkhDJwHwuB2hG361LbGkYfaGa3kGz1\nk5+ff8EZZ5yRgYcX8Zd4wjEYSxBLJHAOHOCcI+GS++LOkXCOoBlZwQChgAHQF43TH03QH43jgHAo\nQHYwQFYoQFbQCAWMYCBAMGDE4gmiCZf8HE8+XjSeYDCewIBQIEAoaAQDRjzhiMUd0USCeGLimfRZ\nwQAl+dmU5GcTChjOQWd/lI6+KL2D8eHnNFsV5WZRFgmTlx0EwDlo7xukpXuQgViCxDQ8ucHDNc3O\nufIT+Z5MBH3anHN3AncCVFVVuerq6ul8eJllhpbnMLNJj91S186zNc1kBwOEs4LkZgW56owKSvKz\njzu2Pxrnldp2atv6qG3tpa6tj7beQXoGYvQMxojGHG85Zz7vv2wZkfDxfyIt3QO8UtfO5oPtvFrf\nQVd/jFgiGb45oSAfe+MqLl1Zdsz3HOns5/O/2MrW+k4G44lkkMcT5GYHiYRDRHJCBM042NpLW290\n3OdpQDhg5GYF6R6IkQAGU/tCBmeX5nPm/EKygsn7OtjaR3P3AHEgPs59FmQFqCzOY+GcXBbMycU5\nR3P3IC09A3T0RinKy6I8EqaiMExJXjbZoUDyDSYYIDtow7djCccvNtfzXE0LfaEAFy0v5aUDbUQH\nYiyOZHPZyjIqCnMozsumJD+LvOwQWcHUm1DqDStgyTeXgEHyx26YQTSWoGcwRvdAnJ6BGFnBQPJ1\nC4fIzQ5idvTNECAYsOH764vGae4aoLl7gNaeKHnZQYrysijOy6Yg52gNwdTxzkHCOZyD7oEYHX2D\ntPdGqWns5sfVtXT1xzhraTHnVM7hwZfqiPdG2TA3wuWrysnLDpKTHSQnFCQ3O0hOVoBwKEg4FEjV\nFBh+fsGADT/H5PNNfnYu+abdOxijZyBONJ4gP/Vc88MhzltcfGDCP4axfm/SWevGzJYCDzvn1o2x\n79+A3zjn7kvd3gVc4Zw7rkU/koJextPWM8i9Lxzgnt8doHcwxoI5ucwvymFZWT63XbWSioKcY46v\nbe1l4zeepmfw2CibWxjm9pvO46LlpcPbNte289c/3sy+5h4gGSbzCnMojWSTn538Q+odjPHC3lZK\n8rP5qzes4B0XVLK5tp3f7m7i6T1N7G1Kfm/AYPXcAkoj2QQsGSyvNfVwsLWXD1y6jE9vXENOVpBf\nbTvMZ362hf5ogo3r5pGTdfQPvy8ap7s/Rld/lFjCUVmcx7KyPJaW5lNeECY71SoPBQPkZwcpyMki\nJyuAmRGNJ2jtGaSpa4B4wrFqboS87OPfmHoHY7R0D6aCbpDugRil+WHmFoapKMihMDeU1ptpunYf\n6eKHz+/n2T3NXLK8lLeeu4CLlpUQCs7+QX7dAzF+/GItdz+7j4aOPt545lze97qlXLKiNKOv4UTM\nbJNzruqEvicDQX89cBvwZuAi4Hbn3IbJ7lNBP3t99bFdFOaGeM/FS8YMlpEaOvoAmF+UO+4xsXiC\nw5391Lb28di2w/z4xVr6onGuWFPOsrJ8Gtr7aejoY8fhLs5aUMh9H7qYnKzkv86JhONdd73A1vpO\nHrrtUkojYQZicWpbe/mbB7ZwoKWHT167hg+9fjnf/U0N33qyhnmFOfzt9Wdy5vxCFszJIRwKHlfT\n5tp2vvarXTyzp3l4W05WgIuWlfK6FaWcu2gO6xYWkT+qxd83GOeff7mDe353gNVzI6yvnMMDm+pY\nt7CQb950HivKI2m/zjJzxeIJeqNxCnOypv2xT0nQm9l9wBVAGXAE+AcgC8A5d4cl38a+TXJkTi/w\nfufcpAk+m4PeOcfLte2sr5xDMDA97+JjaezqJxp3LJwzfohm2rZDHVx/+7MAlOZn85dvWH5c4Dvn\neK6mhR8+v48ndjbiHJxTWcSbzprHG8+cS2vPIJtr23mltp1tDR0cau8f7vsNBYwbzl3ILZcvZ828\ngmMe+5evNvBXP3qJd1xQyVfecQ5mxg+e28cX/ns7X/6Ts3nnhYuPOb6rP8rnHnyVh7c0UJyXRVtv\nlLedt5Av3HBW2n+gL+xt4YW9LVywpJgLl5YMv8FM5je7GvnUT7fQ1DXAX16+nE9eu4bs0Oxv0Yr3\nTlmL/lTwIujjCYcBgZMM56Fwuft9VVx1xtzMFDcFf/yd53DALz586bQ95v9+aBv/+fuD3PFn5/OD\n5/bzzJ5minKzqCzOHe4zPdDaS01jN6X52dy8YTGRnBC/3HqYV2rbj7mvJaV5nL2wiKWl+VQW51JZ\nnMeaeQWUF4THffyvP76b25/Ywz/80VouX13Om7/5DJeuLOP7f1415r/Ozjl+9PuD/OC5fXzsjat5\n6/oFGX9NxtPRG+VwZ/9xb1giJ2MqQT+tJ2O99hf//iKlkTBfvXH9pMd+64k9bDrYxjdvOo+i3KOt\nv631HfzzIzsBqG/rO2W1Tmb3kS4217YTDgWIJ9y0/GcxEIvzi831XLN2Lledkfyo3t/K/S/W0tYz\nSNdAjMOd/RTnZfG1G9dz/Tnzh1vAt75hBYfa+3hmTxMVBTmsXzRnzBOlk/n41avY2dDJP/7PDpb8\n7gC52UH+5e1nj9s/ama85+IlvOfiJSf13KeiKC+Lorzp/9deZLTTJuj7o3GerWk+7kTeWF7Y28LX\nHt8NwHvu+j33fnADc/Ky6R6I8ZH7XqYkP5sjXf00dQ9Ock+nzgPVyRGtA7EE9W19LC7Ny9h9JxKO\ng629LC3LP2b7EzsaaeuN8o6qyuFtVUtLqFpaktb9LpiTe1z3yokKBIyvv/Nc3v7d59h9pJtv3Xwe\nFYWT/0xFTmenTafhq/UdROOO+vY+2nvHD+jugRif+ukrLCnN49vvOo9dh7t4912/p61nkM//YisH\nWnr4xk3nUpKXTVPXwDQ+g6Oi8QT/9XL9cN/8nsaujN7/1x7fxRVf/Q2/3n7kmO0PVNcyrzCHy1ed\n0BDejIuEQ9z7wYv43rvP54+msStGZLY6bYK+en/b8NfbD3WOe9w/PbKDurY+vnbjet5yzgL+7b0X\nsKexm+u++QwPvlTPbVet4uLlpZRFwjR3exP0T+1spLl7kE9euxqAmsbujN13XVsv/++ZfZjBZx/c\nMvwcj3T289vdTbz9/IWenoAeMrcwh+vO1gRskXScNkG/6UAbZZHkSb7tDWMH/W93N/Gfvz/Ih16/\nfLg74so1Fdz13iraege5cGkxH71qJQBlBd616B/YVEd5QZi3rl9AeUGYPRkM+n99dBcBgx+870I6\n+2J87sFXcc7xs5fqSDi4sWpRxh5LRKbHaRH0zjleOtjGFWvKmVeYM2aLvqMvymd+uoWVFRE+cc3q\nY/Zdvrqcp/7mCu794EXDkz7KM9Si/48XDnDjHc+ztym9sG7uHuCpnY28/byFhIIBVpZH0mrR7zzc\nyVcf28XDWw5xsKWXsUZbvXSwjYdeOcQtr1/OFWsq+PTGNTy+/Qg/qa7lp9V1XLi0mGWj+u1FZOY7\nLU7G7mvuobVnkKolxbT2DLJtjKD/+cv1HO7s58H3vG7MsdILRo1VH+q6cc6d1Iy4e363n91Hurnh\n28/xf995Lm9cO/FwzZ+/XE8s4bgxdUJ01dwID75UP2kd339mHw9sqhu+XZyXxXVnz+cT16ymLBLG\nOcc/Pryd8oIwf/mGFQB84NJlPLGjkb/7+VaiccetV6yY8vMUEe+cFi366gPJ/vkLlhSzdn4hNU3d\n9EePnS7/bE0zi0pyOX9xcVr3WV4Qpj+aoHsgNuW66tp62X2kmw9cuowlZXn8xT3VfP3x3STGWTjK\nOccD1XWcu2gOKyuSY7NXVkToHohxpHPi/y5qmrrZsLSEhz9yGV962zquXFPBT16s5cqv/IY7n36N\nn2+u56WD7Xzq2jXDsz0DAeNrf7qenKwgedlBrlefuMisdFq06Dftb6MoN4sV5RHWLigknnDsOdLN\n2ZVFQHI68wuvtfCW9ekH2VB/f3P3IAVTnAb91M5GAN598WI+vXENf/tfW7n9iT00tPfxr6mZnyNt\nqetg15EuvvS2oytRrKxITqnf09jFvKKxhxk656hp7OaPz13IuoVFrFtYxLsvWsKHr1rJl/5nB/+U\nmhdw5vxC/uSCymO+d8GcXO56bxXtfdHjpvuLyOxwWrToNx1s4/zFcwgEjLMWFALJqfxDXq3voGsg\ndtyKgxMZmr15Midkn9zZyJLSPJaX5ZOTFeSrN57DbVeu5IFNddz7wrEL1LX3DvKJn2ymKDeLt5xz\ndEjhUNBP1E/f1DVAV39s+NghK8oj3P2+C/n3D2zg9avK+NLb1o05ouai5aW86ax5U36eIuIt3zfR\n2nsHqWns5m3nLQRgUXEekXDomJE3z9UkF666ZMQqh5M52qKfWtD3DcZ5/rUWbt6weLjlbmZ84prV\n7Gjo5P/893bWzi+kamkJ/dE4t9yzidrWPu794IZjZuqWR8IU5WZNOPJmaN/ooB/yhtXlvGG1t2Pj\nReTU8X2L/qWDR/vnIdnvfOb8gmNG3jxb08za+YWURsZfY2W0k23RP/9aMwOxBFefWXHM9qGZn5XF\nufzVj17icEc/n3zgFf6wv5Wv/un6Y5bcheSbw8qKiUfe1EwS9CLib74P+ur9bYQCxvrKOcPb1s4v\nZEdDJ4mEo28wzksH2rlsVfrdNgAl+dkEbOot+id3NpKXHWTDsuOXDyjKzeLf/qyK7v4YG7/5NP+z\npYHPXXfGuAtyrUoj6AtyQlRMsFiYiPiX/4P+QBtnLSgkN/vokMm1CwrpGYxzoLWXF/e3MhhPnFD/\nPCSvDlOSH55Si945x1M7G7lsZdmYa6EDrJlXwL++4xzae6O895Il3HL58nHvb2VFhNaeQVrGedOp\naexmZUVk2i6MICIzi6/76KPxBK/UtvOui45dSOusBcnRNtsPdbKlrp2soHHh0vSGVY5UFsmeUot+\n15EuDnX089GrV0143B+tX8CFS0uYWxieMKRHnpAdq/tpT2M3V65RH7zI6crXLfpthzoZiCWoWnJs\n98jKigihgLG9oYPnXmvm/MXFk14paSzlBVNr0T+ZGlZ55RkVkxwJ84pyJm2Jr5qbHFNfM8bs2o7e\nKM3dA+qfFzmN+TroN6UmSlWNaq3nZAVZWRHh2ZoWth3q5LIT7LYZklwG4cSXKn5qZyPrFhYyN0PL\n6y4oyiEvO8ieI8cHfU1TcmXLVXMV9CKnK1933ew50kVpfvaYgbp2fiEPvlwPwOumGvSpFv1kyw/8\nevsRjnT1k5cdJBQIsOlAG7dduXJKjzmWoZE3r43Roh8ecVOuqxyJnK58HfT7W3qOu3jGkLULkkEf\nCYdYn5ohe6LKImEG4wk6+2PHjG0fqbM/yofurWb0GmLXrM3sBKSV5RGef63luO17jnQTDgVYWDx9\n15UVkZll1gf9Fx/ezpVrKsYcHnmgpZdLVow9CWptaobsxctLh1ekPFEjx9KPF/S1rb04B//y9rO5\naHkpvYMxsoIBVs/NbAt75dwID75cT1d/9JglGWqaulleHpkRa8iLiDdmdR99TWMX3392Hz/dVHvc\nvv5onIaOfpaWjt2iP2tBEZFwiGvPmvrFvdOZHVvbmryu7LqFRSwry+esBUUZD3lItujh+KUQahq7\nWaUTsSKntVkd9I9tS17qbqzRJgdaegFYMs61VItys3jhf13NjaMW8ToR6cyOrWtL1rGoOHPXdB3L\n8MibEUHfOxijvr1PI25ETnOzOugf3XoYgNcae45b2nd/Sw/AhBfKiIRDJzWJqCySDUzcoq9r66Mg\nHKIw99T2ki0qzqUgHOLxEdd53dvUg3Na+kDkdDdrg76urZdX6ztYXpZPXzTOoY6+Y/YfSAX9kpJT\nd0Wk4rxsggGbsEVf29pLZUneKZ+VGgoG+NDly/nV9iPD6/tojRsRgVkc9EPdNkNXPRrdN72/pZfi\nvCyK8qa2Vnw6AgGjNH/i2bF1bX1UTtOIlw9etoyySJh/eWTn8Br0wYCNe55CRE4PszboH93awBnz\nCrg6Nbt0dNAfaOlhyTQEXNkEk6acc9S29Z7y/vkh+eEQH3/jKv6wv5UndzZS09jNktI8skOz9scs\nIhkwKxOgsauf6gNtXLduPqWRMMV5WcdNFtrf3MvScU7EZtJEyyC09gzSOxhnUcn0jWF/54WLWFaW\nz5cf3cnuI13Do3FE5PQ1K4P+8e1HcA42rktOOlpVUXBMi74/1Wc/3mSpTBq6SPhY6tqS5w0qp6lF\nD5AVDPCpN61h95Fu9jb3qH9eRGZn0D+69TDLyvJZnVq/ZcWo9djr2pKTlKajb7q8IBn0bvTUV6B2\naGjlNLboAa5bN4/1i5Lr72uNGxGZdUHf0Rvld6+18Kaz5g2PZFlZEaGtNzq8Hvv+5onH0GdSWSSb\naNzR0Rc9bt/QZKnpbNFDcu2bv7/+TMoi2Vyw+PgLm4jI6WXWBf0TO48QS7jhbhs4/gLZQ2Pop6tF\nD2NPmqprS478iYSnf6WJqqUlVP/dNSyehjc7EZnZZl3QP7ylgflFOZyz8OhCZMNB33Q06ItysyjO\nzz7l9ZSnlkFoGqOfvratj0UlCloR8dasCvpD7X38Zlcjf3J+JYERi3QNrcc+1KI/0DI9I25gkhZ9\na++0jaEXERnPrAr6n1TX4kgOIRzJzFhRHjmm62Y6xtDDyIXNjh1Ln0g46tr7pm0MvYjIeGZN0Mfi\nCX78Yi2vX1U+ZnfIyooIrzV2MxhLUN/WN20t+qLcLLKCxy+D0NQ9wGAsQaW6bkTEY2kFvZltNLNd\nZlZjZp8dY3+Rmf23mb1iZtvM7P2ZLvS3u5to6OjnXRsWj7l/ZUWEQx397DrcRcIxbS365DIIx4+l\nH1q1Ul03IuK1SYPezILAd4DrgLXAzWa2dtRhHwa2O+fWA1cAXzOzjJ4Jve8PBykvCHP1mWNfUHtF\nagboEzuTa+BMx2SpIWPNjh0aWqmuGxHxWjot+g1AjXNur3NuELgfuGHUMQ4osOTA9gjQCsQyVWRD\nRx9P7mzkT6sqyRrnalBDI2+e2NEIMG1dN5AcSz+6RV/bqha9iMwM6QT9QmDkJZzqUttG+jZwJnAI\neBX4mHMuMfqOzOwWM6s2s+qmpqa0i/zxi7UkHNx04djdNpCcHBUKGK/Wd1AQDlEyDUMrh4zVoq9r\n66O8IExOVnDa6hARGUumTsa+CdgMLADOBb5tZoWjD3LO3emcq3LOVZWXl6d1x/GES52ELZtwTHpW\nMDDcXbOk7NSv/z5SWSRMS88g0fjR97bkqpVqzYuI99IJ+npg5HjGytS2kd4PPOiSaoB9wBmZKPCZ\nPcmTsO++aPzW/JChlRqne/31C5YUE084Htp8aHhbbVvvtC99ICIylnSC/kVglZktS51gvQl4aNQx\nB4GrAcxsLrAG2JuJAncd7gLg0pVlkx471E8/3UF/1RkVrJ1fyLefqiEWTxCLJ2ho75/2xcxERMYy\nadA752LAbcBjwA7gJ865bWZ2q5ndmjrsi8DrzOxV4AngM8655kwU2NQ1QG5WMK31YoaCfjoWMxvJ\nzPjo1avY19zDw1saONzZTyzhNOJGRGaEtFbbcs49AjwyatsdI74+BFyb2dKSGrsGKC8Ip9XnvmFZ\nCSvK89mwbPpXbLx27VzOmFfA7U/u4R9vWAdM/6qVIiJjmfEzYxu7+qlIrSczmQVzcnnik1dM22Sp\nkQKBZKt+b1MPdzyd7LVS142IzASzIOgHqChML+i9tvGseayeG+Hp3U2YwfwiBb2IeG/GB31T1wAV\nBTlel5GWQMD4yFWrAJhfmKOLcovIjDCjk6g/GqerPza8FPBs8Oaz57N6boSVcwu8LkVEBEjzZKxX\nGjuTs01nU9AHA8b9t1zidRkiIsNmdNA3dfcDpH0ydqaYzuUXREQmM6O7bmZji15EZKaZ2UGfWihs\ntpyMFRGZiWZ00Dd1DRAMGKXqChERmbIZHfSNXf2URbKPuRC4iIicmBke9APqnxcROUkzO+g7Z89k\nKRGRmWpGB31T98CsG1opIjLTzNigjyccLQp6EZGT5lnQD0SPu6TsMVq6B0g4jaEXETlZngV9TVP3\nhPuHxtCXq49eROSkeBb0CefoG4yPu79paLLULFmiWERkpvK0j765e2DcfY1dyXVuyiMKehGRk+Fp\n0A91z4ylqUvr3IiIZIKnQd80QdA3dg1QlJtFTlZwGisSEfEfb4N+oq6bTg2tFBHJBG/76Cds0fer\n20ZEJAM8C/pQwCZs0WtWrIhIZngY9IFx++idc8mum0KNoRcROVneBX3Qxg36zv4YA7GEWvQiIhng\nadCPN45eQytFRDLH864b59xx+4YnSynoRUROmmdBnxU0BmIJugZix+1r0rViRUQyxtMWPYw9aUpd\nNyIimeNpHz2MPZa+sWuAcChAYU5oussSEfEd71v0Y5yQbezsp6IwjJkuCi4icrI8b9GP1XXT2KVr\nxYqIZIqnM2NDgbHH0jd1DWh5YhGRDPF0rZvSSPaYY+kbuwZ0wRERkQxJK+jNbKOZ7TKzGjP77DjH\nXGFmm81sm5n9Np37LS8IH9ei74/G6eiLalasiEiGTDqsxcyCwHeAa4A64EUze8g5t33EMXOA7wIb\nnXMHzawinQcvj4SPOxnb0JGcLDVX69yIiGREOi36DUCNc26vc24QuB+4YdQx7wIedM4dBHDONabz\n4GO16Hc2dAKwZl5BOnchIiKTSCfoFwK1I27XpbaNtBooNrPfmNkmM3vvWHdkZreYWbWZVTc1NVEW\nCdPSPUgicXQZhB0NnQQMVs9V0IuIZEKmTsaGgAuA64E3AX9vZqtHH+Scu9M5V+WcqyovL6e8IEws\n4Wjviw4fs72hi+XlEV1CUEQkQ9IJ+npg0YjblaltI9UBjznnepxzzcDTwPrJ7nhoiYOR3Tc7Gjo5\nc35hGmWJiEg60gn6F4FVZrbMzLKBm4CHRh3zC+AyMwuZWR5wEbBjsjseGis/FPQdfVHq2/s4c766\nbUREMmXSUTfOuZiZ3QY8BgSBu51z28zs1tT+O5xzO8zsUWALkADucs5tney+y4Za9N3JkTZDJ2LV\nohcRyZy0Vg1zzj0CPDJq2x2jbn8F+MqJPPhQ101z1yCQ7LYBWKugFxHJGE9nxhaEQ4RDgeGx9Dsa\nuijNz9ZkKRGRDPI06M3smLH021MnYrVqpYhI5nga9ABlkWTQx+IJdh3p0olYEZEM8zzoywvCNHcP\nsK+5h8FYQidiRUQybEYEfVPXANs14kZE5JTwPugjYVp7B9la30FW0FhRHvG6JBERX/E+6AvCOAfP\n1rSwsqKA7JDnJYmI+IrnqVqWmh2bXPpAJ2JFRDLN86AvHzFmXhOlREQyz/OgHzk5SidiRUQyz/Og\nL4so6EVETqW01ro5lXKzg0TCIfLDQUrys70uR0TEdzwPeoD5RTksLsnzugwREV+aEUH/rXedRyQ8\nI0oREfGdGZGuZ8xT37yIyKni+clYERE5tRT0IiI+p6AXEfE5Bb2IiM8p6EVEfE5BLyLicwp6ERGf\nU9CLiPicgl5ExOcU9CIiPqegFxHxOQW9iIjPKehFRHxOQS8i4nMKehERn1PQi4j4nIJeRMTnFPQi\nIj6noBcR8TkFvYiIz6UV9Ga20cx2mVmNmX12guMuNLOYmb0jcyWKiMjJmDTozSwIfAe4DlgL3Gxm\na8c57svArzJdpIiITF06LfoNQI1zbq9zbhC4H7hhjOM+AvwMaMxgfSIicpLSCfqFQO2I23WpbcPM\nbCHwNuB7E92Rmd1iZtVmVt3U1HSitYqIyBRk6mTsN4DPOOcSEx3knLvTOVflnKsqLy/P0EOLiMhE\nQmkcUw8sGnG7MrVtpCrgfjMDKAPebGYx59zPM1KliIhMWTpB/yKwysyWkQz4m4B3jTzAObds6Gsz\n+yHwsEJeRGRmmDTonXMxM7sNeAwIAnc757aZ2a2p/Xec4hpFROQkpNOixzn3CPDIqG1jBrxz7n0n\nX5aIiGSKZsaKiPicgl5ExOcU9CIiPqegFxHxOQW9iIjPKehFRHxOQS8i4nMKehERn1PQi4j4nIJe\nRMTnFPQiIj6noBcR8TkFvYiIzynoRUR8TkEvIuJzCnoREZ9T0IuI+JyCXkTE5xT0IiI+p6AXEfE5\nBb2IiM8p6EVEfE5BLyLicwp6ERGfU9CLiPicgl5ExOcU9CIiPqegFxHxOQW9iIjPKehFRHxOQS8i\n4nMKehERn1PQi4j4nIJeRMTn0gp6M9toZrvMrMbMPjvG/neb2RYze9XMnjez9ZkvVUREpmLSoDez\nIPAd4DpgLXCzma0dddg+4A3OubOBLwJ3ZrpQERGZmnRa9BuAGufcXufcIHA/cMPIA5xzzzvn2lI3\nXwAqM1umiIhMVTpBvxCoHXG7LrVtPB8EfjnWDjO7xcyqzay6qakp/SpFRGTKMnoy1syuJBn0nxlr\nv3PuTudclXOuqry8PJMPLSIi4wilcUw9sGjE7crUtmOY2TnAXcB1zrmWzJQnIiInK50W/YvAKjNb\nZmbZwE3AQyMPMLPFwIPAnznndme+TBERmapJW/TOuZiZ3QY8BgSBu51z28zs1tT+O4DPA6XAd80M\nIOacqzp1ZYuISLrMOefJA1dVVbnq6mpPHltEZLYys00n2pDWzFgREZ9T0IuI+JyCXkTE5xT0IiI+\np6AXEfFTuXhaAAAGKklEQVQ5Bb2IiM8p6EVEfE5BLyLicwp6ERGfU9CLiPicgl5ExOcU9CIiPqeg\nFxHxOQW9iIjPKehFRHxOQS8i4nMKehERn1PQi4j4nIJeRMTnFPQiIj6noBcR8TkFvYiIzynoRUR8\nTkEvIuJzCnoREZ9T0IuI+JyCXkTE5xT0IiI+p6AXEfE5Bb2IiM8p6EVEfE5BLyLicwp6ERGfU9CL\niPicgl5ExOfSCnoz22hmu8ysxsw+O8Z+M7PbU/u3mNn5mS9VRESmYtKgN7Mg8B3gOmAtcLOZrR11\n2HXAqtTHLcD3MlyniIhMUTot+g1AjXNur3NuELgfuGHUMTcA97ikF4A5ZjY/w7WKiMgUhNI4ZiFQ\nO+J2HXBRGscsBBpGHmRmt5Bs8QMMmNnWE6r21CsDmr0uYgwzsS7VlB7VlL6ZWNdMrGnNiX5DOkGf\nMc65O4E7Acys2jlXNZ2PP5mZWBPMzLpUU3pUU/pmYl0ztaYT/Z50um7qgUUjblemtp3oMSIi4oF0\ngv5FYJWZLTOzbOAm4KFRxzwEvDc1+uZioMM51zD6jkREZPpN2nXjnIuZ2W3AY0AQuNs5t83Mbk3t\nvwN4BHgzUAP0Au9P47HvnHLVp85MrAlmZl2qKT2qKX0zsS5f1GTOuVNRiIiIzBCaGSsi4nMKehER\nn/Mk6CdbUmGaarjbzBpHjuU3sxIze9zM9qQ+F09zTYvM7Ckz225m28zsY17XZWY5ZvYHM3slVdMX\nvK5pRG1BM3vZzB6eQTXtN7NXzWzz0DA4r+syszlm9lMz22lmO8zsEo9/p9akXp+hj04z+/gMeJ3+\nOvU7vtXM7kv97ntd08dS9Wwzs4+ntp1wTdMe9GkuqTAdfghsHLXts8ATzrlVwBOp29MpBnzSObcW\nuBj4cOq18bKuAeAq59x64FxgY2pkldevFcDHgB0jbs+EmgCudM6dO2L8tdd1fRN41Dl3BrCe5Gvm\nWU3OuV2p1+dc4AKSAzj+y8uazGwh8FGgyjm3juTAk5s8rmkd8CGSqxOsB95iZiunVJNzblo/gEuA\nx0bc/hzwuemuI/XYS4GtI27vAuanvp4P7PKirhH1/AK4ZqbUBeQBL5GcGe1pTSTnajwBXAU8PFN+\nfsB+oGzUNs/qAoqAfaQGXsyEmkbVcS3wnNc1cXR2fwnJ0YgPp2rzsqYbge+PuP33wKenUpMXXTfj\nLZcwE8x1R8f/HwbmelWImS0FzgN+j8d1pbpINgONwOPOOc9rAr5B8pc+MWKb1zUBOODXZrYpteSH\n13UtA5qAH6S6ue4ys3yPaxrpJuC+1Nee1eScqwe+ChwkuXRLh3PuV17WBGwFXm9mpWaWR3II+6Kp\n1KSTseNwybdLT8aemlkE+Bnwcedcp9d1OefiLvlvdiWwIfUvpWc1mdlbgEbn3KbxjvHw53dZ6rW6\njmTX2+Ue1xUCzge+55w7D+hh1L/6Xr1WqQmYbwUeGL3Pg9+pYpKLMy4DFgD5ZvYeL2tyzu0Avgz8\nCngU2AzEp1KTF0E/k5dLOGKpVTdTnxunuwAzyyIZ8j9yzj04U+oCcM61A0+RPLfhZU2XAm81s/0k\nV1O9ysz+w+OagOGWIc65RpL9zhs8rqsOqEv9FwbwU5LB7/lrRfLN8CXn3JHUbS9reiOwzznX5JyL\nAg8Cr/O4Jpxz33fOXeCcuxxoA3ZPpSYvgj6dJRW88hDw56mv/5xkH/m0MTMDvg/scM59fSbUZWbl\nZjYn9XUuyXMGO72syTn3OedcpXNuKcnfnyedc+/xsiYAM8s3s4Khr0n28W71si7n3GGg1syGVjy8\nGtjuZU0j3MzRbhvwtqaDwMVmlpf6O7ya5Elrr3+nKlKfFwNvB/5zSjVN14mFUScZ3kzynek14G89\nquE+kn1xUZKtng8CpSRP8O0Bfg2UTHNNl5H8N2wLyX/TNqdeK8/qAs4BXk7VtBX4fGq7p6/ViPqu\n4OjJWK9/fsuBV1If24Z+t2dAXecC1amf4c+B4hlQUz7QAhSN2OZ1TV8g2YjZCtwLhGdATc+QfGN+\nBbh6qq+TlkAQEfE5nYwVEfE5Bb2IiM8p6EVEfE5BLyLicwp6ERGfU9CLiPicgl5ExOf+P+Dcl7SK\n1BHgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20d62641588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(cost_history.shape)\n",
    "plt.plot(range(len(cost_history)),cost_history)\n",
    "plt.axis([0,training_epochs,0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing time : 241 seconds\n"
     ]
    }
   ],
   "source": [
    "sess.close()\n",
    "end_time = time.time()\n",
    "print(\"processing time : %d seconds\" % (end_time - start_time,))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
